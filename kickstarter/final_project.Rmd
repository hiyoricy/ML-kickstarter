---
title: "[CATCHY TITLE]"
author:
- Hoyt Gong
- Younghu Park
- Hiyori Yoshida
output:
  pdf_document:
    toc: yes
    toc_depth: '4'
  html_document:
    code_folding: show
    highlight: haddock
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.height=4, fig.width=6, warning = F)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr, ggplot2, tidyverse, jsonlite, lubridate, zoo, tm)

```

# Summary 

# Description of the Problem

First, some terms are defined to help explain how Kickstarter works. 

A **creator** is the person or team behind a project idea. 

A **project** is a finite work with a clear goal for which a creator is seeking funding.

The **funding goal** is the amount of money that a creator seeks to raise for their project. 

**Backers** are people who **pledge** money to help creators make their projects a reality. 

Creators who seek funding on Kickstarter want their projects to succeed so they can bring their ideas to life. Funding on Kickstarter is all-or-nothing. This means the creator will not receive the money people have pledged toward their project unless the project reaches its funding goal. Thus, "success" in this case is reaching the funding goal. As demonstrated in Kickstarter's [Creator Handbook](https://www.kickstarter.com/help/handbook?ref=whatarebasics), creators put a lot of effort into designing their project, funding, promotion, and communication to increase their chances of reaching their funding goal. 

The goal of this paper is to use attributes of existing Kickstarter projects in classifiers to predict whether a project will succeed or fail. Determining the atrributes of a project that are most valuable in predicting success can help creators design their projects to maximize their chances of reaching their funding goal. 

# Description of the Data

[Web Robots](https://webrobots.io/kickstarter-datasets/) has been scraping data from Kickstarter projects monthly starting March 2016. The most recent data from November 2019 is used in this project. The response variable that is predicted in this project is `successful`, a categorical variable that is either 1 for "successful" or 0 for "failed". The original data includes "canceled" as a state, which are converted to "failed". This is because it is assumed that canceled projects would likely have failed. The following independent variables are considered in the analysis: 

|Independent Variable|Description|
|-----------------|--------------------------------|
| `backers_count` | The number of backers that have pledged some amount of money to the project. |
| `blurb` | A short summary at the top of project pages that describe/promote the project. |
| `category` | The category of the project. This dataset includes 160 different categories, including "public Art," "software," "narrative film," etc. |
| `slug` -> `description`| Select keywords to describe the project, renamed to description |
| `converted_pledged_amount` | The amount pledged to the project in USD. |
| `country` | The country in which the project is based. | 
| `location` | The city and state in wich the project is based. |
| `deadline` | The date and time of the deadline until which the project will raise funds. After the deadline, the project is determined to be "successful" or "failed" depending on whether it reached its funding goal. |
| `launched_at` | The date and time at which the project was made public and started raising funds. |
| `duration_days` | deadline - launched_at. The fundraising duration of the project in days. |
| `goal` | The funding goal of the project. |
| `name` | The title of the project. |
| `usd_pledged` | The amount pledged towards the project in USD. |
| `staff_pick` | True if the Kickstarter staff have chosen to feature the project in their "Projects We Love" program, false otherwise. 

# Data Cleaning and Preparation

```{r}
#to import dataset
kick_data <- read.csv("kick_data.csv", header=TRUE)
```

```{r}
head(kick_data)
```

```{r}
dim(kick_data)
```

```{r}
colnames(kick_data)
```

```{r}
#filtering out duplicate entries by keeping the most recent item and additionally filtering by the unique column number in X
kick_data.f <- kick_data %>% group_by(id)%>% filter(state_changed_at == max(state_changed_at)) %>% filter(X == max(X)) %>% rename(sub_id=X)
```


```{r}
#selecting columns to use, temporarily selecting id columns for merging and identification
to_use<- c("id", "sub_id",  "state", "backers_count", "blurb", "slug", "category", "converted_pledged_amount", "country","location", "deadline", "launched_at", "goal", "name","usd_pledged","staff_pick", "spotlight")
kick_data.f <- kick_data.f %>% select(to_use)

```


```{r}
#converting launched_at and deadline to datetime formats
dts <- kick_data.f$launched_at
mydates = dts
class(mydates) = c('POSIXt','POSIXct')
kick_data.f$launched_at <- as.Date(mydates)

dts <- kick_data.f$deadline
mydates = dts
class(mydates) = c('POSIXt','POSIXct')
kick_data.f$deadline <-  as.Date(mydates)
```


```{r}
#calcuation duration of project in days
kick_data.f$duration_days <- as.numeric(difftime(kick_data.f$deadline ,kick_data.f$launched_at , units = c("days")))
```

```{r}
#parsing our json data to extract categories 
ParseJSONColumn <- function(x)  {
     str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]") %>% 
      fromJSON(flatten = T) %>% 
     as.tibble()
} 

JSONcolumn_data <- kick_data.f  %>% 
    select(id, category)  %>% 
    map_dfc(.f = ParseJSONColumn)  %>% select(value, name, slug) %>% rename(id = value, category = name, subcategory = slug)


kick_data.f <- kick_data.f %>% select(-category) %>% rename(description=slug)

kick_data.f <-  merge(kick_data.f, JSONcolumn_data ,by="id")

```

```{r}
#extracting locations through string splits
parsed_location <- kick_data.f %>% separate(location, c("foo", "bar"), '\"displayable_name\":\"') %>% select(foo,bar) %>% separate(bar, c("location", "foo2"), '\",\"') %>%  separate(location, c("foo", "location"), ', ')  %>% select(location)

kick_data.f$location <- parsed_location$location

northeast =c('CT', 'ME', 'MA', 'NH', 'RI', 'VT', 'NJ', 'NY', 'PA')
midwest = c('IL', 'IN', 'MI', 'OH', 'WI', 'IA', 'KS', 'MN', 'MO', 'NE', 'ND', 'SD')
west =c('AZ', 'CO', 'ID', 'MT', 'NV', 'NM', 'UT', 'WY', 'AL', 'CA', 'HI', 'OR', 'WA')
south = c('MD', 'DE', 'VA', 'WV','KY','TN','NC', "SC", "FL", "GA", "AL", "MS", "LA", "AK", "TK", "OK")
kick_data.f$location <- ifelse(kick_data.f$location %in% northeast, "US-Northeast", ifelse(kick_data.f$location %in% midwest, "US-Midwest", ifelse(kick_data.f$location %in% west, "US-West", ifelse(kick_data.f$location %in% south, "US-South", kick_data.f$location))))
```


```{r}
#converting types of columns
kick_data.f$location <- as.factor(kick_data.f$location)
kick_data.f$blurb <- as.character(kick_data.f$blurb)
kick_data.f$description <- as.character(kick_data.f$description)
kick_data.f$name <- as.character(kick_data.f$name)
kick_data.f$category <- as.factor(kick_data.f$category)
```

```{r}
#replacing dashes with spaces in descriptions column and removing _truncated_ tag in blurb
kick_data.f$description <- gsub("-", " ",kick_data.f$description)
```

```{r}
#creating predictor column
kick_data.f$successful<- as.factor(as.numeric(ifelse(kick_data.f$state=="successful", 1, 0)))
```


```{r}
#filtering out the live projects, but storing them in a seperate place
kick_data.f.live <- kick_data.f %>% filter(state=="live")
kick_data.f <- kick_data.f %>% filter(state != "live")
```

```{r}
#double checking that we all desired columns and removing ids
to_use<- c("state", "successful", "backers_count", "blurb", "category", "description", "converted_pledged_amount", "country","location", "deadline", "launched_at", "duration_days", "goal", "name","usd_pledged","staff_pick", "spotlight")


kick_data.f <- kick_data.f %>% select(to_use)
```

```{r}
#final state
str(kick_data.f)
```


```{r}
mycorpus1 <- VCorpus( VectorSource(kick_data.f$blurb))
mycorpus1
typeof(mycorpus1)   ## It is a list
# inspect the first corpus 
inspect(mycorpus1[[1]])
# or use `as.character` to extract the text
as.character(mycorpus1[[1]])
```

```{r}
mycorpus_clean <- tm_map(mycorpus1, content_transformer(tolower))
mycorpus_clean <- tm_map(mycorpus_clean, removeWords, stopwords("english"))
mycorpus_clean <- tm_map(mycorpus_clean, removePunctuation)
mycorpus_clean <- tm_map(mycorpus_clean, removeNumbers)
mycorpus_clean <- tm_map(mycorpus_clean, stemDocument, lazy = TRUE)   
lapply(mycorpus_clean[4:5], as.character)
```


```{r}
dtm1 <- DocumentTermMatrix( mycorpus_clean )   ## library = collection of words for all documents
dtm1
```


```{r}
threshold <- .005*length(mycorpus_clean)   # 1% of the total documents 
words.10 <- findFreqTerms(dtm1, lowfreq=threshold)  # words appearing at least among 1% of the documents
length(words.10)

dtm.10<- DocumentTermMatrix(mycorpus_clean, control = list(dictionary = words.10))  
dim(as.matrix(dtm.10))
colnames(dtm.10)[1:50]
```

```{r}
names(data)
# Combine the original data with the text matrix
data1.temp <- data.frame(kick_data.f,as.matrix(dtm.10) )   
dim(data1.temp)
names(data1.temp)[1:30]
str(data1.temp)
# data2 consists of date, rating and all the top 1% words
#ata2 <- data1.temp[, c(1,7, 8,11, 14:ncol(data1.temp))]
#names(data2)[1:20]
#dim(data2)
```

```{r}
data2
```




```{r}
y <- data1.temp$successful
X <- as.matrix(data1.temp[, -c(1,2)]) # we can use as.matrix directly here
set.seed(2)

#### Be careful to run the following LASSO.
result.lasso <- cv.glmnet(X, y, alpha=.99, family="binomial")  # 10 minutes in my MAC
#save(result.lasso, file="/Users/lzhao/Dropbox/STAT471/Data/TextMining.RData")

### or try `sparse.model.matrix()` which is much faster
#X1 <- sparse.model.matrix(successful~., data=data1.temp)[, -1]
#dim(X1)
#result.lasso.1 <- cv.glmnet(X1, y, alpha=.99, family="binomial")  # 1.5 minutes in my MAC
#plot(result.lasso.1)
plot(result.lasso)
```



# Models

## Logistic Regression

## Random Forest

# Comparison of Methods 

# Final Model 

# Validity of Results and Future Improvement

# Conclusion

# Appendix

# Works Cited

