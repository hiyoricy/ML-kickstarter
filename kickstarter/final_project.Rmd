---
title: "[CATCHY TITLE]"
author:
- Hoyt Gong
- Younghu Park
- Hiyori Yoshida
output:
  pdf_document:
    toc: yes
    toc_depth: '4'
  html_document:
    code_folding: show
    highlight: haddock
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.height=4, fig.width=6, warning = F)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr, ggplot2, glmnet, tidyverse, jsonlite, lubridate, zoo)


```

# Summary 

# Description of the Problem

First, some terms are defined to help explain how Kickstarter works. 

A **creator** is the person or team behind a project idea. 

A **project** is a finite work with a clear goal for which a creator is seeking funding.

The **funding goal** is the amount of money that a creator seeks to raise for their project. 

**Backers** are people who **pledge** money to help creators make their projects a reality. 

Creators who seek funding on Kickstarter want their projects to succeed so they can bring their ideas to life. Funding on Kickstarter is all-or-nothing. This means the creator will not receive the money people have pledged toward their project unless the project reaches its funding goal. Thus, "success" in this case is reaching the funding goal. As demonstrated in Kickstarter's [Creator Handbook](https://www.kickstarter.com/help/handbook?ref=whatarebasics), creators put a lot of effort into designing their project, funding, promotion, and communication to increase their chances of reaching their funding goal. 

The goal of this paper is to use attributes of existing Kickstarter projects in classifiers to predict whether a project will succeed or fail. Determining the atrributes of a project that are most valuable in predicting success can help creators design their projects to maximize their chances of reaching their funding goal. 

# Description of the Data

[Web Robots](https://webrobots.io/kickstarter-datasets/) has been scraping data from Kickstarter projects monthly starting March 2016. The most recent data from November 2019 is used in this project. The response variable that is predicted in this project is `successful`, a categorical variable that is either 1 for "successful" or 0 for "failed". The original data includes "canceled" as a state, which are converted to "failed". This is because it is assumed that canceled projects would likely have failed. The following independent variables are considered in the analysis: 

|Independent Variable|Description|
|-----------------|--------------------------------|
| `backers_count` | The number of backers that have pledged some amount of money to the project. |
| `blurb` | A short summary at the top of project pages that describe/promote the project. |
| `category` | The category of the project. This dataset includes 160 different categories, including "public Art," "software," "narrative film," etc. |
| `slug` -> `description`| Select keywords to describe the project, renamed to description |
| `country` | The country in which the project is based. | 
| `location` | The city and state in wich the project is based. |
| `deadline` | The date and time of the deadline until which the project will raise funds. After the deadline, the project is determined to be "successful" or "failed" depending on whether it reached its funding goal. |
| `launched_at` | The date and time at which the project was made public and started raising funds. |
| `duration_days` | deadline - launched_at. The fundraising duration of the project in days. |
| `goal` | The funding goal of the project. |
| `name` | The title of the project. |
| `usd_pledged` | The amount pledged towards the project in USD. |
| `staff_pick` | True if the Kickstarter staff have chosen to feature the project in their "Projects We Love" program, false otherwise. 

# Data Cleaning and Preparation

```{r}
#to import dataset
kick_data <- read.csv("kick_data.csv", header=TRUE)
```

```{r}
head(kick_data)
```

```{r}
dim(kick_data)
```

```{r}
colnames(kick_data)
```

```{r}
#filtering out duplicate entries by keeping the most recent item and additionally filtering by the unique column number in X
kick_data.f <- kick_data %>% group_by(id)%>% filter(state_changed_at == max(state_changed_at)) %>% filter(X == max(X)) %>% rename(sub_id=X)
```


```{r}
#selecting columns to use, temporarily selecting id columns for merging and identification
to_use<- c("id", "sub_id",  "state", "backers_count", "blurb", "slug", "category", "converted_pledged_amount", "country","location", "deadline", "launched_at", "goal", "name","usd_pledged","staff_pick", "spotlight")
kick_data.f <- kick_data.f %>% select(to_use)

```


```{r}
#converting launched_at and deadline to datetime formats
dts <- kick_data.f$launched_at
mydates = dts
class(mydates) = c('POSIXt','POSIXct')
kick_data.f$launched_at <- as.Date(mydates)

dts <- kick_data.f$deadline
mydates = dts
class(mydates) = c('POSIXt','POSIXct')
kick_data.f$deadline <-  as.Date(mydates)
```


```{r}
#calcuation duration of project in days
kick_data.f$duration_days <- as.numeric(difftime(kick_data.f$deadline ,kick_data.f$launched_at , units = c("days")))
```

```{r}
#parsing our json data to extract categories 
ParseJSONColumn <- function(x)  {
     str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]") %>% 
      fromJSON(flatten = T) %>% 
     as.tibble()
} 

JSONcolumn_data <- kick_data.f  %>% 
    select(id, category)  %>% 
    map_dfc(.f = ParseJSONColumn)  %>% select(value, name, slug) %>% rename(id = value, category = name, subcategory = slug)


kick_data.f <- kick_data.f %>% select(-category) %>% rename(description=slug)

kick_data.f <-  merge(kick_data.f, JSONcolumn_data ,by="id")

```

```{r}
#extracting locations through string splits
parsed_location <- kick_data.f %>% separate(location, c("foo", "bar"), '\"displayable_name\":\"') %>% select(foo,bar) %>% separate(bar, c("location", "foo2"), '\",\"') %>%  separate(location, c("foo", "location"), ', ')  %>% select(location)

kick_data.f$location <- parsed_location$location

northeast =c('CT', 'ME', 'MA', 'NH', 'RI', 'VT', 'NJ', 'NY', 'PA')
midwest = c('IL', 'IN', 'MI', 'OH', 'WI', 'IA', 'KS', 'MN', 'MO', 'NE', 'ND', 'SD')
west =c('AZ', 'CO', 'ID', 'MT', 'NV', 'NM', 'UT', 'WY', 'AL', 'CA', 'HI', 'OR', 'WA')
south = c('MD', 'DE', 'VA', 'WV','KY','TN','NC', "SC", "FL", "GA", "AL", "MS", "LA", "AK", "TK", "OK")
kick_data.f$location <- ifelse(kick_data.f$location %in% northeast, "US-Northeast", ifelse(kick_data.f$location %in% midwest, "US-Midwest", ifelse(kick_data.f$location %in% west, "US-West", ifelse(kick_data.f$location %in% south, "US-South", kick_data.f$location))))
```


```{r}
#converting types of columns
kick_data.f$location <- as.factor(kick_data.f$location)
kick_data.f$blurb <- as.character(kick_data.f$blurb)
kick_data.f$description <- as.character(kick_data.f$description)
kick_data.f$name <- as.character(kick_data.f$name)
kick_data.f$category <- as.factor(kick_data.f$category)
```

```{r}
#replacing dashes with spaces in descriptions column and removing _truncated_ tag in blurb
kick_data.f$description <- gsub("-", " ",kick_data.f$description)
```

```{r}
#creating predictor column
kick_data.f$successful<- as.factor(as.numeric(ifelse(kick_data.f$state=="successful", 1, 0)))
```


```{r}
#filtering out the live projects, but storing them in a seperate place
kick_data.f.live <- kick_data.f %>% filter(state=="live")
kick_data.f <- kick_data.f %>% filter(state != "live")
```

```{r}
#double checking that we all desired columns and removing ids
to_use<- c("state", "successful", "backers_count", "blurb", "category", "description", "converted_pledged_amount", "country","location", "deadline", "launched_at", "duration_days", "goal", "name","usd_pledged","staff_pick", "spotlight")


kick_data.f <- kick_data.f %>% select(to_use)
```

```{r}
kick_data.f <- subset(kick_data.f, select = -converted_pledged_amount)
```


```{r}
#final state
str(kick_data.f)
```

```{r}
# split data into training and testing sets 
set.seed(10)
#First randomly sample a quarter of the data for computational purposes
sample.size <- round(dim(kick_data.f) * 0.25)
index.sample <- sample(nrow(kick_data.f), sample.size)
data <- kick_data.f[index.sample, ] #dim(data) = 21381    16
# use the 70/30 rule: set the training dataset size to be 70% of data size and testing to be 30%
train.size <- round(dim(data) * 0.7)
index.t <- sample(nrow(data), train.size)
train <- data[index.t, ] #dim(train) = 14967    16
test <- data[-index.t, ] #dim(test) = 6414    16
```


# Model Overview

# Models

## LASSO

```{r}
# Prepare the design matrix and response for LASSO
X <- model.matrix(successful ~ data$backers_count + data$category
                  + data$country + data$deadline + data$launched_at
                  + data$duration_days + data$goal + data$usd_pledged + data$staff_pick, data)[, -1]
Y <- data$successful
dim(X)
length(Y)
```

```{r}
set.seed(10) # to have same sets of K folds
fit1.cv <- cv.glmnet(X, Y, alpha=.9, family="binomial", nfolds = 10, type.measure = "deviance")  
plot(fit1.cv)
```

fit1.cv\$lambda.1se is chosen because it has fewer variables.

```{r include=FALSE}
coef.1se <- coef(fit1.cv, s="lambda.1se")  
coef.1se <- coef.1se[which(coef.1se !=0),] #pull out coefficients that aren't 0 
coef.1se   
```

Replacing the variables for which factor levels (`categoryPunk`, `countryMX`) are outputted by the above Elastic Net with the corresponding categorical variable, the following eight variables are outputted by Elastic Net: `category`, `country`, `duration_days`, `staff_pick`, `backers_count`, `deadline`, `goal`, and `usd_pledged`. 

## Logistic Regression

To locate a set of important features, a logistic regression using `glm()` is run with the variables obtained from Elastic Net above on the training dataset.

```{r include = FALSE}
fit.logit.1 <- glm(successful ~ category + country + duration_days + staff_pick + backers_count
                   + deadline + goal + usd_pledged, family=binomial, data=train)
summary(fit.logit.1)
```
```{r include=FALSE}
Anova(fit.logit.1)
```

### Backward Elimination 

Backward elimination is performed to only keep variables that are significant at the 0.01 level. 

First, `staff_pick` is removed because it has the highest p-value. 

```{r, include=FALSE}
# Remove staff_pick because it has highest the p-value
fit.logit.2 <- update(fit.logit.1, .~. -staff_pick)
Anova(fit.logit.2)
```

After backward elimination, the following seven variables are significant in the logistic regression model: `category`, `country`, `duration_days`, `backers_count`, `deadline`, `goal`, `usd_pledged`.

### Evaluate Logistic Regression Model 

## Random Forest





# Comparison of Methods 

# Final Model 

# Validity of Results and Future Improvement

# Conclusion

# Appendix

# Works Cited

